# ğŸ› ï¸ Integration and Comparison of vision models for smart inspection cell


This repository contains the implementation and evaluation of a **deep learningâ€“based computer vision system** for automated surface defect inspection of automotive spur gears. The project focuses on detecting and classifying common manufacturing defects using **YOLOv8** and **MobileNetV2**, with an emphasis on **accuracy, robustness, and inference latency**.

---

## ğŸ“Œ Project Overview

Surface defects such as **scratches, dents, cracks, and pitting** can significantly affect the reliability of automotive spur gears. Traditional inspection methods are often subjective and difficult to scale. This project explores a **data-driven vision-based approach** using deep learning models to automate defect inspection and evaluate their feasibility for industrial deployment.

---

## ğŸ¯ Project Objectives

- Train **YOLOv8** for defect detection and localization  
- Train **MobileNetV2** for lightweight image-level defect classification  
- Compare both models using industrial performance metrics  
- Measure inference latency and runtime behavior  
- Assess feasibility for real-world inspection scenarios  

---

## ğŸ“‚ Dataset Generation Pipeline

The dataset used in this project is **synthetically generated** to overcome the lack of publicly available spur gear defect datasets.

**Workflow:**
1. Spur Gear CAD Modeling (CATIA â€“ defect-free geometry)  
2. Defect Modeling (Onshape â€“ scratch, dent, crack, pitting)  
3. Synthetic Image Generation (multiple views, lighting, orientations)  
4. Manual Annotation (LabelImg â€“ YOLO `.txt` format)  
5. Dataset Split (Train / Validation / Test)

---

## ğŸ§  Models Used

### ğŸ”¹ YOLOv8 (Object Detection)
- Task: Defect detection and localization  
- Input size: 640 Ã— 640  
- Metrics: Precision, Recall, F1-score, mAP@50, mAP@50â€“95  

### ğŸ”¹ MobileNetV2 (Image Classification)
- Task: Component-level defect classification  
- Input size: 224 Ã— 224  
- Metrics: Accuracy, Precision, Recall, F1-score  

---

## ğŸ“Š Evaluation Metrics

The models are evaluated using the following metrics:

- **Accuracy** â€“ Overall correctness of predictions  
- **Precision** â€“ Correct defect detections among predicted defects  
- **Recall** â€“ Ability to detect all actual defects  
- **F1-score** â€“ Balance between precision and recall  
- **mAP@50 / mAP@50â€“95** â€“ Localization performance (YOLOv8)  
- **Inference Latency** â€“ Time required for single-image inference  
- **Throughput** â€“ Number of components inspected per unit time  

---


---

## ğŸ§ª Experimental Setup

- Platform: Google Colab  
- GPU: NVIDIA Tesla T4  
- Frameworks: PyTorch, Ultralytics YOLOv8  
- Batch size: 1  




### 1ï¸âƒ£ Clone the repository
```bash
git clone https://github.com/Pallelayaswitha1/Integration-and-Comparison-of-vision-models-for-smart-inspection-cell/tree/main
cd Integration-and-Comparison-of-vision-models-for-smart-inspection-cell 








